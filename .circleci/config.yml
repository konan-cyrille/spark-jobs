# Python CircleCI 2.1 configuration file

version: 2.1
jobs:
  # Job to test convert_csv_file
  build_test:
    docker:
      - image: circleci/python:3.8.10

    working_directory: ~/repo

    steps:
      # step1 : fetch repo from Github
      - checkout
      # step2 : Create virtual environnment and install dependencies
      - run:
          name: install dependencies
          command: |
            echo '****1'
            sudo apt-get update
            echo '****2'
            sudo apt-get install -y default-jre default-jdk
            echo '****3'
            sudo apt-get update
            echo '****3-bis'
            sudo apt-get install -y curl
            echo '****4'
            curl -L -O https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz
            echo '****5'
            tar xvf spark-3.2.0-bin-hadoop3.2.tgz
            echo '****6'
            sudo mv spark-3.2.0-bin-hadoop3.2/ /opt/spark
            echo '****7'

            export SPARK_HOME=/opt/spark
            export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin

            python3 -m venv venv
            . venv/bin/activate
            pip install -r requirements.txt
      #step3: run tests
      - run:
          name: run tests
          command: |
            . venv/bin/activate
            pytest -v --cov=convert_csv_files_to_parquet_file
  
workflows:
  build_and_test_before_push_to_git:
    jobs:
      - build_test
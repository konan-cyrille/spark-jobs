# Python CircleCI 2.1 configuration file

version: 2.1
jobs:
  # Job to test convert_csv_file
  build_test:
    docker:
      - image: circleci/python:3.8.10

    working_directory: ~/repo

    steps:
      # step1 : fetch repo from Github
      - checkout
      # step2 : Create virtual environnment and install dependencies
      - run:
          name: install dependencies
          command: |
            echo "************** Java version"
            java -version
            sudo apt-get install default-jre
            sudo apt-get install default-jdk

            wget https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz
            tar xvf spark-3.2.0-bin-hadoop3.2.tgz
            sudo mv spark-3.2.0-bin-hadoop3.2/ /opt/spark

            export SPARK_HOME=/opt/spark
            export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin

            python3 -m venv venv
            . venv/bin/activate
            pip install -r requirements.txt
      #step3: run tests
      - run:
          name: run tests
          command: |
            . venv/bin/activate
            pytest -v --cov=convert_csv_files_to_parquet_file
  
workflows:
  build_and_test_before_push_to_git:
    jobs:
      - build_test